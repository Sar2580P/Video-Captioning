# -*- coding: utf-8 -*-
"""Pre_trained_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bjtkecANrt-LSSfZgneUEt2HOTqlyCwP
"""


import keras
import tensorflow as tf
from keras.layers import Dense, Activation, Flatten
from keras.applications.vgg16 import  preprocess_input

# Extracting temporal features

def load_videos(vid_frames):
    vid_tensor = tf.image.resize(vid_frames, (224, 224))
    vid_tensor = preprocess_input(vid_tensor)     # meant to adequate your image to the format (VGG16) requires.

    return vid_tensor

class cnn_model(keras.layers.Layer):
  def __init__(self):
    """
      A sequence of conv_layers that first apply the conv_operation over the
      spatial dims, and then the temporal dims. 
    """
    super().__init__()
    self.vgg = tf.keras.applications.vgg16.VGG16(
                                                          include_top=True,
                                                          weights='imagenet',
                                                        )
    self.vgg.trainable = False
    
    new_input = self.vgg.input # Any arbitrary shapes with 3 channels
    hidden_layer = self.vgg.layers[-3].output    

    self.img_features_extract_model = tf.keras.Model(new_input, hidden_layer)
    print("Using VGG-16")

  def call(self, x):
    sz = x.shape
    x = load_videos(x)
    x = self.img_features_extract_model(x)
    return x 

####################################################################################################
# Extracting temporal features

class cnn_3D_video(keras.layers.Layer):
  def __init__(self , model):
    super().__init__()
    self.model = model

  def call(self, x):
    n_vid = x.shape[0]
    x = tf.convert_to_tensor(x)    # [None, None, None ,3]
    x = self.model(x)['default'][0]
    x = tf.reshape(x, (n_vid, -1))
    return x