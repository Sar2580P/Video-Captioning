{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dIi_-6XuQJij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2550e53f-350c-4ff1-b675-a8210fac5b1c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "Ffwl-8qbYr4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f94d890-31f7-4463-963f-913606a1a818"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-m1xhse1c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-m1xhse1c\n",
            "  Resolved https://github.com/tensorflow/docs to commit 4d512c2d7c40d69fcb842978aeaa136e19abe2bb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.5.26.9808) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.5.26.9808) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.5.26.9808) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.5.26.9808) (5.9.0)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.5.26.9808) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.5.26.9808) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2023.5.26.9808) (2.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.5.26.9808) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.5.26.9808) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==2023.5.26.9808) (3.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import nltk\n",
        "import time\n",
        "import os\n",
        "\n",
        "from text_utilities import *\n",
        "from video_utilities import *\n",
        "from pipeline_attention_utilities_new import *\n",
        "from pre_trained_models import *\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.translate.meteor_score  import  single_meteor_score as meteor_"
      ],
      "metadata": {
        "id": "ILpGpMDxjQm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e656dc7f-a869-401e-e2fa-f39cfaa9456d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model Weights"
      ],
      "metadata": {
        "id": "WZc0IzzcjWz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 256\n",
        "units = 256\n",
        "vocab_size = 10929\n",
        "# checkpoint_path_ckpt = \"/content/drive/MyDrive/Video_Cap_Data/Checkpoints\"\n",
        "BATCH_SIZE = 1"
      ],
      "metadata": {
        "id": "iSRIcPmiXFFw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Video_Cap_Data/Pickles/Tokenizer.pkl'\n",
        "tokenizer = pickle.load(open(path, 'rb'))      # rb --> read binary\n",
        "tokenizer.index_word[0]"
      ],
      "metadata": {
        "id": "Ovv-zD9ntZ0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07a0f1f3-d56e-40f8-87f9-868074b1e3db"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "k_FoE_YnOpNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4095dd90-2aa3-445c-dbb8-0224fc5e2a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Uniform entropy: 9.30\n",
            "Marginal entropy: 5.81\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fb098b4ca00>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "encoder_2d = Encoder(embedding_dim)\n",
        "encoder_3d = Encoder(embedding_dim)\n",
        "decoder = Decoder(tokenizer, BATCH_SIZE, units, vocab_size, embedding_dim)\n",
        "\n",
        "\n",
        "encoder_2d.load_weights('/content/drive/MyDrive/Video_Cap_Data/Pickles/encoder_vgg/weights' )  # creates a HDF5 file 'my_model.h5'\n",
        "encoder_3d.load_weights('/content/drive/MyDrive/Video_Cap_Data/Pickles/encoder_movinet/weights' )  # creates a HDF5 file 'my_model.h5'\n",
        "decoder.load_weights('/content/drive/MyDrive/Video_Cap_Data/Pickles/decoder/weights')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CqKqdWwOXE6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/drive/MyDrive/Video_Cap_Data/Pickles/df_train.pkl\", \"rb\")\n",
        "df_tst = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "df_tst = df_tst.iloc[:50000 , :]\n",
        "df_tst.head(3)\n"
      ],
      "metadata": {
        "id": "URAKFFvG1yWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "45cf7e06-d95c-4895-972b-3e50fe5e9509"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category   video_id   time  \\\n",
              "0         2  video2960  12.32   \n",
              "1         2  video2960  12.32   \n",
              "2         2  video2960  12.32   \n",
              "\n",
              "                                             caption  split  \\\n",
              "0  <start>  cartoon animals runs through an ice c...  train   \n",
              "1  <start>  cartoon character runs around inside ...  train   \n",
              "2    <start>  character is running in the snow <end>  train   \n",
              "\n",
              "                                                path  \n",
              "0  /content/drive/MyDrive/Video_Cap_Data/Train_Va...  \n",
              "1  /content/drive/MyDrive/Video_Cap_Data/Train_Va...  \n",
              "2  /content/drive/MyDrive/Video_Cap_Data/Train_Va...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdabe540-0450-4a0c-add6-845ad79cb189\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>video_id</th>\n",
              "      <th>time</th>\n",
              "      <th>caption</th>\n",
              "      <th>split</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>video2960</td>\n",
              "      <td>12.32</td>\n",
              "      <td>&lt;start&gt;  cartoon animals runs through an ice c...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/Video_Cap_Data/Train_Va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>video2960</td>\n",
              "      <td>12.32</td>\n",
              "      <td>&lt;start&gt;  cartoon character runs around inside ...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/Video_Cap_Data/Train_Va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>video2960</td>\n",
              "      <td>12.32</td>\n",
              "      <td>&lt;start&gt;  character is running in the snow &lt;end&gt;</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/Video_Cap_Data/Train_Va...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdabe540-0450-4a0c-add6-845ad79cb189')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdabe540-0450-4a0c-add6-845ad79cb189 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdabe540-0450-4a0c-add6-845ad79cb189');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path_tst = '/content/drive/MyDrive/Video_Cap_Data/Train_Val_videos/TrainValVideo'\n",
        "\n",
        "idx = random.randint(0, len(df_tst) )\n",
        "vid_id = df_tst.iloc[idx , 1]\n",
        "caption = df_tst.iloc[idx , 3]\n",
        "vid_ids = [vid_id]\n",
        "\n",
        "# seqs = get_seqs(tokenizer, caption , 74)"
      ],
      "metadata": {
        "id": "E58LY13Gi-YK"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gh_2d =  FrameGenerator(vid_ids, base_path_tst,224, 20)\n",
        "frames_2d, vid_id = next(gh_2d())\n",
        "\n",
        "gh_3d =  FrameGenerator(vid_ids, base_path_tst,224, 100 , 2)\n",
        "frames_3d, vid_id = next(gh_3d())"
      ],
      "metadata": {
        "id": "97J3lmEuwNJ-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_3d = frames_3d[1:]\n",
        "frames_2d.shape , frames_3d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz6yoIp-GIlk",
        "outputId": "dc226ba5-e831-4f63-ecd7-e8c1a0edb29c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((21, 224, 224, 3), (100, 224, 224, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_captions(vid_id ):\n",
        "  df =  df_tst[df_tst['video_id']== vid_id]\n",
        "  return df.iloc[0 , 3]"
      ],
      "metadata": {
        "id": "aUjQA8-A720r"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_captions(vid_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rIJOUVFNyNe5",
        "outputId": "611423d2-1724-4412-ac69-0aa6d03774b0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start>  cartoon dog is holding binoculars <end>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_2d_path = os.path.join('/content/drive/MyDrive/Video_Cap_Data/features_2d', vid_id[5:]+'.npy')\n",
        "\n",
        "features_3d_path = os.path.join('/content/drive/MyDrive/Video_Cap_Data/features_3d', vid_id+'.npy')\n",
        "\n",
        "tensor_2d = tf.constant(np.load(features_2d_path ))\n",
        "tensor_3d = tf.constant(np.load(features_3d_path ))\n",
        "\n",
        "tensor_2d.shape , tensor_3d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZxkH797zAzB",
        "outputId": "9bdd839b-2366-4315-9de2-0b7186dc9f44"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([21, 4096]), TensorShape([5, 80]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sz = tensor_2d.shape\n",
        "if sz[0]!=21:\n",
        "  diff_2d = 20- sz[0]\n",
        "  a = tf.zeros((diff_2d, 4096))\n",
        "  tensor_2d = tf.concat([a, tensor_2d], 0)\n",
        "\n",
        "sz = tensor_3d.shape\n",
        "if sz[0]!=5:\n",
        "  diff_3d = 5- sz[0]\n",
        "  a = tf.zeros((diff_3d, 480))\n",
        "  tensor_3d = tf.concat([a, tensor_3d], 0)\n",
        "\n",
        "tensor_2d = tf.expand_dims(tensor_2d, axis= 0)\n",
        "tensor_3d = tf.expand_dims(tensor_3d, axis= 0)\n",
        "\n",
        "\n",
        "tensor_2d.shape , tensor_3d.shape"
      ],
      "metadata": {
        "id": "ao1R3X5r--m3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b175994e-83d3-4672-ff41-21f164161539"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 21, 4096]), TensorShape([1, 5, 80]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 42\n",
        "\n",
        "dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 0)\n",
        "h = tf.zeros((BATCH_SIZE, units))\n",
        "c = tf.zeros((BATCH_SIZE, units))\n",
        "\n",
        "features_2d = encoder_2d(tensor_2d)\n",
        "features_3d = encoder_3d(tensor_3d)\n",
        "features_2d.shape , features_3d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LUqZh8hHbcG",
        "outputId": "e24a077c-93f8-4302-a3a7-0fec46c538c3"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 21, 256]), TensorShape([1, 5, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_seqs =None\n",
        "for i in range(1, max_len):\n",
        "\n",
        "  pred, h, c = decoder(dec_input, features_2d, features_3d, h ,c)\n",
        "\n",
        "  dec_input = tf.argmax(pred, axis =-1, output_type=tf.dtypes.int32)\n",
        "  if tokenizer.index_word[dec_input[0][0].numpy()]=='<end>':\n",
        "    break\n",
        "  if pred_seqs == None:\n",
        "    pred_seqs = dec_input\n",
        "  pred_seqs = tf.concat([pred_seqs, dec_input], axis= 1)\n"
      ],
      "metadata": {
        "id": "hwV-SyU59KQc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_caption = tokenizer.sequences_to_texts(pred_seqs.numpy())\n",
        "pred_caption = ' '.join(pred_caption)\n",
        "real_caption = get_captions(vid_id)\n",
        "\n",
        "real = real_caption.split(' ')\n",
        "real_caption = ' '.join(real[1:-1])"
      ],
      "metadata": {
        "id": "4_3A20o599u1"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('pred_caption : ' , pred_caption)\n",
        "print('real_caption : ' , real_caption[1:])\n",
        "print('Meteor score : ' , meteor_(real_caption.split() , pred_caption.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zcLz8RBMGtj",
        "outputId": "fd00b03a-5b16-4f20-acb8-2999be032ba4"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_caption :  man man is talking about the video game\n",
            "real_caption :  cartoon dog is holding binoculars\n",
            "Meteor score :  0.09433962264150944\n"
          ]
        }
      ]
    }
  ]
}